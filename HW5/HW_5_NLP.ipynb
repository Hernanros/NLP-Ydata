{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "Copy of HW_5_NLP.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hernanros/NLP-Ydata/blob/master/HW5/HW_5_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdV92T_1GUVN",
        "colab_type": "text"
      },
      "source": [
        "# HW5 - Rating prediction using Amazon's Reviews\n",
        "    \n",
        "In this exercise, you'll train a text classification on a **subset** of the the Amazon's Reviews dataset. \n",
        "\n",
        "The Amazon's Reviews dataset  contains product reviews and metadata from Amazon, including 142.8 million reviews spanning May 1996 - July 2014.\n",
        "\n",
        "\n",
        "We will focus on the Home and Kitchen segment which contains ~550k reviews and can be downloaded here: http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Home_and_Kitchen_5.json.gz\n",
        "\n",
        "You will predict the rating that was given to a product from the review.\n",
        "\n",
        "The dataset contains the following fields for each review, in JSON format:\n",
        "1. \"reviewerID\": \"A11N155CW1UV02\",\n",
        "1. \"asin\": \"B000H00VBQ\",\n",
        "1. \"reviewerName\": \"AdrianaM\"\n",
        "1. \"helpful\": [0, 0]\n",
        "1. \"reviewText\": \"I had big expectations because I love English TV, in particular Investigative and detective stuff but this guy is really boring. It didn't appeal to me at all.\"\n",
        "1. \"overall\": 2.0\n",
        "1. \"summary\": \"A little bit boring for me\"\n",
        "1. \"unixReviewTime\": 1399075200\n",
        "1. \"reviewTime\": \"05 3, 2014\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Please note that the **only** two fields that you are allowed to use in this exercise are \"reviewText\" which contains the review and \"overall\" which contains the rating. Other than that you have the **option** to use the \"asin\" field which is a unique product identifier. You may (or may not :) ) find this field useful. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vH0ExGViGUWC",
        "colab_type": "text"
      },
      "source": [
        "## General guidelines\n",
        "\n",
        "1. You are required to implement at least two models.\n",
        "1. The first should be a CNN or an RNN (or a combination) and should include the use of Glove embeddings.\n",
        "1. The second model should be implemented using the transformers package and include Transfer learning concepts that were mentioned in the Lecture.\n",
        "1. Pay attention to any preprocessing steps that are needed.\n",
        "1. Feel free to be creative and use any method which was mentioned in the lectures (e.g., tf-idf, pos,...) extra points will be given to creativity.\n",
        "1. The main criteria for evaluation is not the over-all score but rather the entire process (preprocessing, efficient training ...)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Su6nahkUpASC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "7dd9b89c-ea7f-4475-e628-b8854c482fe5"
      },
      "source": [
        "!wget http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Home_and_Kitchen_5.json.gz"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-18 09:48:04--  http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Home_and_Kitchen_5.json.gz\n",
            "Resolving snap.stanford.edu (snap.stanford.edu)... 171.64.75.80\n",
            "Connecting to snap.stanford.edu (snap.stanford.edu)|171.64.75.80|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 138126598 (132M) [application/x-gzip]\n",
            "Saving to: ‘reviews_Home_and_Kitchen_5.json.gz’\n",
            "\n",
            "reviews_Home_and_Ki 100%[===================>] 131.73M  5.64MB/s    in 31s     \n",
            "\n",
            "2020-06-18 09:48:36 (4.20 MB/s) - ‘reviews_Home_and_Kitchen_5.json.gz’ saved [138126598/138126598]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ls9hwNRwyYkn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e444910f-e9af-4dfe-ec49-fc7d5c532093"
      },
      "source": [
        "! gunzip reviews_Home_and_Kitchen_5.json.gz"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gzip: reviews_Home_and_Kitchen_5.json already exists; do you wish to overwrite (y or n)? y\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bn4dAIv3pDeI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import zipfile"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nR0yM2O6141O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "revs = []\n",
        "for line in open('reviews_Home_and_Kitchen_5.json', 'r'):\n",
        "    try:\n",
        "      revs.append(json.loads(line))\n",
        "    except:\n",
        "      continue"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8gJR5fN2DVr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "59a1aae8-ab1e-49c3-beb5-0aa16503eaa5"
      },
      "source": [
        "df = pd.DataFrame(revs)\n",
        "\n",
        "data = df[['asin','reviewText','overall']]\n",
        "data.head()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>asin</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>overall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0615391206</td>\n",
              "      <td>My daughter wanted this book and the price on ...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0615391206</td>\n",
              "      <td>I bought this zoku quick pop for my daughterr ...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0615391206</td>\n",
              "      <td>There is no shortage of pop recipes available ...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0615391206</td>\n",
              "      <td>This book is a must have if you get a Zoku (wh...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0615391206</td>\n",
              "      <td>This cookbook is great.  I have really enjoyed...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         asin                                         reviewText  overall\n",
              "0  0615391206  My daughter wanted this book and the price on ...      5.0\n",
              "1  0615391206  I bought this zoku quick pop for my daughterr ...      5.0\n",
              "2  0615391206  There is no shortage of pop recipes available ...      4.0\n",
              "3  0615391206  This book is a must have if you get a Zoku (wh...      5.0\n",
              "4  0615391206  This cookbook is great.  I have really enjoyed...      4.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7gJVAp_6al7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "dbfb2fdf-d8fd-4e87-bc35-86001693bc6a"
      },
      "source": [
        "data.groupby('asin').size()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "asin\n",
              "0615391206    11\n",
              "0689027818     5\n",
              "0912696591    93\n",
              "1223070743     8\n",
              "1567120709    16\n",
              "              ..\n",
              "B00L8HA5L8    14\n",
              "B00L9KOZBK     6\n",
              "B00LAI4UYS     5\n",
              "B00LB18EKK    19\n",
              "B00LBFUU12     9\n",
              "Length: 28237, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MatD_2Z2x5L",
        "colab_type": "text"
      },
      "source": [
        "# Workflow\n",
        "Pre-processing:\n",
        "  - tf-idf calculation (where each document might be a review OR a specific user reviews collection)\n",
        "  - ~tokenization~\n",
        "  - POS tagging\n",
        "  - ~embedding~\n",
        "\n",
        "## Model No.1 - RNN + Glove\n",
        "Generally: takes in each review, removes stopwords, transform tokens into embedding, predicts a score.\n",
        "As features:\n",
        "- ~embbeded tokens~\n",
        "- ~product_id (asin)~\n",
        "- ~num reviews for product~\n",
        "- ~len of mean product review length~\n",
        "- num of adjactives\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m60b4f6s2J62",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 682
        },
        "outputId": "e26eff76-58a4-4149-d67f-9b1ff9951bd8"
      },
      "source": [
        "# !wget  http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
        "\n",
        "# z = zipfile.ZipFile(\"./glove.840B.300d.zip\")\n",
        "# glove_pd = pd.read_csv(z.open('glove.840B.300d.txt'), sep=\" \", quoting=3, header=None, index_col=0)\n",
        "# glove = {key: val.values for key, val in glove_pd.T.items()}\n",
        "# del glove_pd"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-18 10:22:22--  http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.840B.300d.zip [following]\n",
            "--2020-06-18 10:22:22--  https://nlp.stanford.edu/data/glove.840B.300d.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip [following]\n",
            "--2020-06-18 10:22:23--  http://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2176768927 (2.0G) [application/zip]\n",
            "Saving to: ‘glove.840B.300d.zip’\n",
            "\n",
            "glove.840B.300d.zip 100%[===================>]   2.03G  2.13MB/s    in 17m 24s \n",
            "\n",
            "2020-06-18 10:39:47 (1.99 MB/s) - ‘glove.840B.300d.zip’ saved [2176768927/2176768927]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-3d4d8c0e1054>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mglove_pd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mwordfreq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mwordfreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_frequency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'en'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwordlist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'large'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'wordfreq'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIgcREjubfGZ",
        "colab_type": "text"
      },
      "source": [
        "# part 1 - pre-processing and feature extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NRD5TXqDaV_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "4f685c8f-b020-4153-fd7f-fb16cc4711fe"
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords \n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize \n",
        "from nltk.stem.porter import *\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "tokenizer = nltk.RegexpTokenizer(r\"\\w+\")"
      ],
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nBfCfaLHoxQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "e1eb356a-7e2e-46a0-9206-b13a46371ccf"
      },
      "source": [
        "toy = data.iloc[np.random.choice(len(data),500),:]\n",
        "toy"
      ],
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>asin</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>overall</th>\n",
              "      <th>tokenized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>122167</th>\n",
              "      <td>B000A68E48</td>\n",
              "      <td>Good product, well built, and works as describ...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>[Good product, well built, and works as descri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>382462</th>\n",
              "      <td>B003YUBQI8</td>\n",
              "      <td>I love these measuring spoons!  They're measur...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>[I love these measuring spoons!, They're measu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>326211</th>\n",
              "      <td>B002R5A178</td>\n",
              "      <td>I love that it folds flat and stores easily wh...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>[I love that it folds flat and stores easily w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132651</th>\n",
              "      <td>B000BVFYUO</td>\n",
              "      <td>For years I had been using a wooden turntable ...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>[For years I had been using a wooden turntable...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>547753</th>\n",
              "      <td>B00IW110B2</td>\n",
              "      <td>The Spiral Slicer is so amazing.  I have seen ...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>[The Spiral Slicer is so amazing., I have seen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138210</th>\n",
              "      <td>B000E9Q0TM</td>\n",
              "      <td>I liked this grinder--good looks, one hand ope...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[I liked this grinder--good looks, one hand op...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>540864</th>\n",
              "      <td>B00GCETRWU</td>\n",
              "      <td>Really charming display for cupcakes. Has a ti...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>[Really charming display for cupcakes., Has a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>385862</th>\n",
              "      <td>B00416XIW6</td>\n",
              "      <td>The Snapware storage containers are the best t...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>[The Snapware storage containers are the best ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>546997</th>\n",
              "      <td>B00IMV7I7W</td>\n",
              "      <td>First of all, this Serta queen-size box spring...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[First of all, this Serta queen-size box sprin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>288897</th>\n",
              "      <td>B001UE8ILS</td>\n",
              "      <td>I've only used this cart twice, so I can't spe...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>[I've only used this cart twice, so I can't sp...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              asin  ...                                          tokenized\n",
              "122167  B000A68E48  ...  [Good product, well built, and works as descri...\n",
              "382462  B003YUBQI8  ...  [I love these measuring spoons!, They're measu...\n",
              "326211  B002R5A178  ...  [I love that it folds flat and stores easily w...\n",
              "132651  B000BVFYUO  ...  [For years I had been using a wooden turntable...\n",
              "547753  B00IW110B2  ...  [The Spiral Slicer is so amazing., I have seen...\n",
              "...            ...  ...                                                ...\n",
              "138210  B000E9Q0TM  ...  [I liked this grinder--good looks, one hand op...\n",
              "540864  B00GCETRWU  ...  [Really charming display for cupcakes., Has a ...\n",
              "385862  B00416XIW6  ...  [The Snapware storage containers are the best ...\n",
              "546997  B00IMV7I7W  ...  [First of all, this Serta queen-size box sprin...\n",
              "288897  B001UE8ILS  ...  [I've only used this cart twice, so I can't sp...\n",
              "\n",
              "[500 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 235
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pij7CrS6GNEM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "18b4310f-53e5-4fd5-d069-947dffd52742"
      },
      "source": [
        "s2i = {w:i for i,w in enumerate(glove.keys())}\n",
        "i2s = {i:w for w,i in s2i.items()}\n",
        "i2v = {i:v for i,v in enumerate(glove.values())}\n",
        "\n",
        "def intranslate(sent):\n",
        "  return np.array([s2i[word] if word in s2i.keys() else 0 for word in sent]).reshape(1,-1)\n",
        "\n",
        "def preprocessor (entry, stopwords):  \n",
        "  #1. remove stop words and punctuation marks:\n",
        "  tokenized = tokenizer.tokenize(entry)\n",
        "  tokenized = [w.lower() for w in tokenized  if not w in stop_words]\n",
        "  return tokenized\n",
        "\n",
        "def embed (sent, embbeding_dict):\n",
        "  return np.array([embbeding_dict[word] if word in embbeding_dict.keys() else np.zeros((1,300)) for word in sent])\n",
        "\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "def adj_count(entry):\n",
        "  return np.sum([1 if pos[1].startswith('JJ') else 0 for pos in np.array(nltk.pos_tag(tokenizer.tokenize(entry)))])\n",
        "\n",
        "def preprocessor_df (toy):\n",
        "\n",
        "  toy['tokenized'] = toy['reviewText'].apply(lambda x: preprocessor(x, stopwords))\n",
        "  toy['len'] = toy['tokenized'].apply(lambda x: len(x))\n",
        "  toy['joined'] = toy['tokenized'].apply(lambda x: ' '.join(x))\n",
        "  toy['int_sentences'] = toy.tokenized.apply(lambda x: intranslate(x))\n",
        "\n",
        "  toy['glove'] = toy.tokenized.apply(lambda x:embed (x, glove))\n",
        "\n",
        "  #add number of reviews as feature\n",
        "  toy = toy.join(toy.groupby('asin')['reviewText'].count(), on = 'asin',rsuffix = '_count')\n",
        "\n",
        "  # remove too long reviews\n",
        "  toy = toy[toy.len < toy.len.quantile(.95)]\n",
        "\n",
        "  #add product mean length as a feature\n",
        "  toy = toy.join(toy.groupby('asin')['len'].mean(), on = 'asin',rsuffix = '_mean')\n",
        "  \n",
        "  #count number of adhuctives in review\n",
        "  toy['num_adjs'] = toy.reviewText.apply(lambda x: adj_count(x))\n",
        "\n",
        "  return toy\n",
        "\n",
        "toy = preprocessor_df(toy)"
      ],
      "execution_count": 285,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Fb2YG8kbll2",
        "colab_type": "text"
      },
      "source": [
        "# part 2 - Bidirectional LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3U6D_VHocnM0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        },
        "outputId": "0c1cfcc2-4958-4f16-872e-4d0f611cc690"
      },
      "source": [
        "data = toy\n",
        "data.head()"
      ],
      "execution_count": 286,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>asin</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>overall</th>\n",
              "      <th>tokenized</th>\n",
              "      <th>len</th>\n",
              "      <th>joined</th>\n",
              "      <th>glove</th>\n",
              "      <th>reviewText_count</th>\n",
              "      <th>len_mean</th>\n",
              "      <th>num_adjs</th>\n",
              "      <th>int_sentences</th>\n",
              "      <th>reviewText_count</th>\n",
              "      <th>len_mean</th>\n",
              "      <th>reviewText_count</th>\n",
              "      <th>len_mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>122167</th>\n",
              "      <td>B000A68E48</td>\n",
              "      <td>Good product, well built, and works as describ...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>[good, product, well, built, works, described,...</td>\n",
              "      <td>19</td>\n",
              "      <td>good product well built works described got tw...</td>\n",
              "      <td>[[-0.42625, 0.4431, -0.34517, -0.1326, -0.0581...</td>\n",
              "      <td>1</td>\n",
              "      <td>19.0</td>\n",
              "      <td>3</td>\n",
              "      <td>[[112, 493, 133, 1178, 647, 1945, 218, 135, 71...</td>\n",
              "      <td>1</td>\n",
              "      <td>19.0</td>\n",
              "      <td>1</td>\n",
              "      <td>19.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>382462</th>\n",
              "      <td>B003YUBQI8</td>\n",
              "      <td>I love these measuring spoons!  They're measur...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>[i, love, measuring, spoons, they, measuring, ...</td>\n",
              "      <td>36</td>\n",
              "      <td>i love measuring spoons they measuring spoons ...</td>\n",
              "      <td>[[0.18733, 0.40595, -0.51174, -0.55482, 0.0397...</td>\n",
              "      <td>1</td>\n",
              "      <td>36.0</td>\n",
              "      <td>4</td>\n",
              "      <td>[[108, 185, 7677, 32659, 49, 7677, 32659, 108,...</td>\n",
              "      <td>1</td>\n",
              "      <td>36.0</td>\n",
              "      <td>1</td>\n",
              "      <td>36.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>326211</th>\n",
              "      <td>B002R5A178</td>\n",
              "      <td>I love that it folds flat and stores easily wh...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>[i, love, folds, flat, stores, easily, use, it...</td>\n",
              "      <td>19</td>\n",
              "      <td>i love folds flat stores easily use it hold mu...</td>\n",
              "      <td>[[0.18733, 0.40595, -0.51174, -0.55482, 0.0397...</td>\n",
              "      <td>1</td>\n",
              "      <td>19.0</td>\n",
              "      <td>4</td>\n",
              "      <td>[[108, 185, 18103, 2488, 2151, 1069, 125, 21, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>19.0</td>\n",
              "      <td>1</td>\n",
              "      <td>19.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132651</th>\n",
              "      <td>B000BVFYUO</td>\n",
              "      <td>For years I had been using a wooden turntable ...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>[for, years, i, using, wooden, turntable, thou...</td>\n",
              "      <td>49</td>\n",
              "      <td>for years i using wooden turntable thought pre...</td>\n",
              "      <td>[[-0.17224, 0.18234, -0.27847, -0.084665999999...</td>\n",
              "      <td>1</td>\n",
              "      <td>49.0</td>\n",
              "      <td>8</td>\n",
              "      <td>[[11, 141, 108, 245, 5387, 38841, 400, 491, 11...</td>\n",
              "      <td>1</td>\n",
              "      <td>49.0</td>\n",
              "      <td>1</td>\n",
              "      <td>49.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>359247</th>\n",
              "      <td>B003G2ZVSA</td>\n",
              "      <td>I ordered this on May 8th and received it in j...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>[i, ordered, may, 8th, received, 4, business, ...</td>\n",
              "      <td>30</td>\n",
              "      <td>i ordered may 8th received 4 business days it ...</td>\n",
              "      <td>[[0.18733, 0.40595, -0.51174, -0.55482, 0.0397...</td>\n",
              "      <td>2</td>\n",
              "      <td>20.0</td>\n",
              "      <td>6</td>\n",
              "      <td>[[108, 3311, 119, 3690, 933, 131, 220, 257, 21...</td>\n",
              "      <td>2</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              asin  ... len_mean\n",
              "122167  B000A68E48  ...     19.0\n",
              "382462  B003YUBQI8  ...     36.0\n",
              "326211  B002R5A178  ...     19.0\n",
              "132651  B000BVFYUO  ...     49.0\n",
              "359247  B003G2ZVSA  ...     20.0\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 286
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUM8ElxtXbhM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n",
        "\n",
        "MAXLEN = np.max(data.len)\n",
        "BATCHSIZE = 32\n"
      ],
      "execution_count": 279,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TbhbwP2cWKi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "05480f3d-9130-4fd5-b6bc-12c45ddfb250"
      },
      "source": [
        "sequence.pad_sequences(data.int_sentences.iloc[0], maxlen=MAXLEN, padding='post', truncating = 'post')"
      ],
      "execution_count": 287,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 112,  493,  133, 1178,  647, 1945,  218,  135, 7106, 3426,  250,\n",
              "        2568, 8438,  751,   27,  158,  493,  158,  423,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 287
        }
      ]
    }
  ]
}