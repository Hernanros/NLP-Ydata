{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "Copy of HW_5_NLP.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hernanros/NLP-Ydata/blob/master/HW5/HW_5_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdV92T_1GUVN",
        "colab_type": "text"
      },
      "source": [
        "# HW5 - Rating prediction using Amazon's Reviews\n",
        "    \n",
        "In this exercise, you'll train a text classification on a **subset** of the the Amazon's Reviews dataset. \n",
        "\n",
        "The Amazon's Reviews dataset  contains product reviews and metadata from Amazon, including 142.8 million reviews spanning May 1996 - July 2014.\n",
        "\n",
        "\n",
        "We will focus on the Home and Kitchen segment which contains ~550k reviews and can be downloaded here: http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Home_and_Kitchen_5.json.gz\n",
        "\n",
        "You will predict the rating that was given to a product from the review.\n",
        "\n",
        "The dataset contains the following fields for each review, in JSON format:\n",
        "1. \"reviewerID\": \"A11N155CW1UV02\",\n",
        "1. \"asin\": \"B000H00VBQ\",\n",
        "1. \"reviewerName\": \"AdrianaM\"\n",
        "1. \"helpful\": [0, 0]\n",
        "1. \"reviewText\": \"I had big expectations because I love English TV, in particular Investigative and detective stuff but this guy is really boring. It didn't appeal to me at all.\"\n",
        "1. \"overall\": 2.0\n",
        "1. \"summary\": \"A little bit boring for me\"\n",
        "1. \"unixReviewTime\": 1399075200\n",
        "1. \"reviewTime\": \"05 3, 2014\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Please note that the **only** two fields that you are allowed to use in this exercise are \"reviewText\" which contains the review and \"overall\" which contains the rating. Other than that you have the **option** to use the \"asin\" field which is a unique product identifier. You may (or may not :) ) find this field useful. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vH0ExGViGUWC",
        "colab_type": "text"
      },
      "source": [
        "## General guidelines\n",
        "\n",
        "1. You are required to implement at least two models.\n",
        "1. The first should be a CNN or an RNN (or a combination) and should include the use of Glove embeddings.\n",
        "1. The second model should be implemented using the transformers package and include Transfer learning concepts that were mentioned in the Lecture.\n",
        "1. Pay attention to any preprocessing steps that are needed.\n",
        "1. Feel free to be creative and use any method which was mentioned in the lectures (e.g., tf-idf, pos,...) extra points will be given to creativity.\n",
        "1. The main criteria for evaluation is not the over-all score but rather the entire process (preprocessing, efficient training ...)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Su6nahkUpASC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "a155408f-2ff1-4ad6-b05b-4d7926c3fea3"
      },
      "source": [
        "!wget http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Home_and_Kitchen_5.json.gz"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-24 11:09:14--  http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Home_and_Kitchen_5.json.gz\n",
            "Resolving snap.stanford.edu (snap.stanford.edu)... 171.64.75.80\n",
            "Connecting to snap.stanford.edu (snap.stanford.edu)|171.64.75.80|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 138126598 (132M) [application/x-gzip]\n",
            "Saving to: ‘reviews_Home_and_Kitchen_5.json.gz’\n",
            "\n",
            "reviews_Home_and_Ki 100%[===================>] 131.73M  15.4MB/s    in 8.8s    \n",
            "\n",
            "2020-06-24 11:09:23 (14.9 MB/s) - ‘reviews_Home_and_Kitchen_5.json.gz’ saved [138126598/138126598]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ls9hwNRwyYkn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! gunzip reviews_Home_and_Kitchen_5.json.gz"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bn4dAIv3pDeI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import zipfile\n",
        "import json"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nR0yM2O6141O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "revs = []\n",
        "for line in open('reviews_Home_and_Kitchen_5.json', 'rb'):\n",
        "    try:\n",
        "      revs.append(json.loads(line))\n",
        "    except:\n",
        "      continue"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8gJR5fN2DVr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "100c0243-50d7-4e45-9850-95e81fb7af3b"
      },
      "source": [
        "df = pd.DataFrame(revs)\n",
        "\n",
        "data = df[['asin','reviewText','overall']]\n",
        "data.head()"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>asin</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>overall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0615391206</td>\n",
              "      <td>My daughter wanted this book and the price on ...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0615391206</td>\n",
              "      <td>I bought this zoku quick pop for my daughterr ...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0615391206</td>\n",
              "      <td>There is no shortage of pop recipes available ...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0615391206</td>\n",
              "      <td>This book is a must have if you get a Zoku (wh...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0615391206</td>\n",
              "      <td>This cookbook is great.  I have really enjoyed...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         asin                                         reviewText  overall\n",
              "0  0615391206  My daughter wanted this book and the price on ...      5.0\n",
              "1  0615391206  I bought this zoku quick pop for my daughterr ...      5.0\n",
              "2  0615391206  There is no shortage of pop recipes available ...      4.0\n",
              "3  0615391206  This book is a must have if you get a Zoku (wh...      5.0\n",
              "4  0615391206  This cookbook is great.  I have really enjoyed...      4.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7gJVAp_6al7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "5cd17f44-6a84-462f-9b1d-94616f566430"
      },
      "source": [
        "data.groupby('asin').size()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "asin\n",
              "0615391206    11\n",
              "0689027818     5\n",
              "0912696591    93\n",
              "1223070743     8\n",
              "1567120709    16\n",
              "              ..\n",
              "B00L8HA5L8    14\n",
              "B00L9KOZBK     6\n",
              "B00LAI4UYS     5\n",
              "B00LB18EKK    19\n",
              "B00LBFUU12     9\n",
              "Length: 28237, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MatD_2Z2x5L",
        "colab_type": "text"
      },
      "source": [
        "# Workflow\n",
        "Pre-processing:\n",
        "  - tf-idf calculation (where each document might be a review OR a specific user reviews collection)\n",
        "  - ~tokenization~\n",
        "  - ~POS tagging~\n",
        "  - ~embedding~\n",
        "\n",
        "## Model No.1 - RNN + Glove\n",
        "Generally: takes in each review, removes stopwords, transform tokens into embedding, predicts a score.\n",
        "As features:\n",
        "- ~embbeded tokens~\n",
        "- ~product_id (asin)~\n",
        "- ~num reviews for product~\n",
        "- ~len of mean product review length~\n",
        "- ~num of adjactives~\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m60b4f6s2J62",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "3b09317f-4ee8-4dde-cda7-f1cb429aee52"
      },
      "source": [
        "!wget  http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
        "\n",
        "z = zipfile.ZipFile(\"./glove.840B.300d.zip\")\n",
        "glove_pd = pd.read_csv(z.open('glove.840B.300d.txt'), sep=\" \", quoting=3, header=None, index_col=0,skiprows=lambda x: x >200000)\n",
        "glove = {key: val.values for key, val in glove_pd.T.items()}\n",
        "del glove_pd"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-24 11:09:39--  http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.840B.300d.zip [following]\n",
            "--2020-06-24 11:09:39--  https://nlp.stanford.edu/data/glove.840B.300d.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip [following]\n",
            "--2020-06-24 11:09:39--  http://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2176768927 (2.0G) [application/zip]\n",
            "Saving to: ‘glove.840B.300d.zip’\n",
            "\n",
            "glove.840B.300d.zip 100%[===================>]   2.03G  2.03MB/s    in 16m 54s \n",
            "\n",
            "2020-06-24 11:26:34 (2.05 MB/s) - ‘glove.840B.300d.zip’ saved [2176768927/2176768927]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIgcREjubfGZ",
        "colab_type": "text"
      },
      "source": [
        "# part 1 - pre-processing and feature extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NRD5TXqDaV_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "0c0c58ee-18ff-4e6d-dabe-acd9c64c72d8"
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords \n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize \n",
        "from nltk.stem.porter import *\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "tokenizer = nltk.RegexpTokenizer(r\"\\w+\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nBfCfaLHoxQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "9f1931e1-e02d-4d3f-f2f4-0fafe5bf1c4f"
      },
      "source": [
        "toy = data.iloc[np.random.choice(len(data),500),:]\n",
        "toy"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>asin</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>overall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>431234</th>\n",
              "      <td>B005447JCY</td>\n",
              "      <td>I love my filter water in these. I washed the ...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494773</th>\n",
              "      <td>B008MWKGH0</td>\n",
              "      <td>Bought 2 of these for our guest rooms (1 gray,...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79799</th>\n",
              "      <td>B00017UT6W</td>\n",
              "      <td>Great quality product.  A good bronze color an...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149988</th>\n",
              "      <td>B000FSFOM6</td>\n",
              "      <td>I bought one of the 20X72 inch mats for my wif...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>342229</th>\n",
              "      <td>B0032SK8XG</td>\n",
              "      <td>I have no complaints about this item.  It is w...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45574</th>\n",
              "      <td>B00008439Y</td>\n",
              "      <td>I bought the Roomba about 6 months ago. It has...</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297464</th>\n",
              "      <td>B0027IS6NG</td>\n",
              "      <td>I opted for this curtain because I didn't want...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399715</th>\n",
              "      <td>B004BA8UWA</td>\n",
              "      <td>So far the king size has lasted and is definit...</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>466357</th>\n",
              "      <td>B006SOHESS</td>\n",
              "      <td>I make frozen yogurt for my pups. They love it...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>367769</th>\n",
              "      <td>B003O47WZA</td>\n",
              "      <td>My daughter loves to bakes.  She especially en...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              asin                                         reviewText  overall\n",
              "431234  B005447JCY  I love my filter water in these. I washed the ...      5.0\n",
              "494773  B008MWKGH0  Bought 2 of these for our guest rooms (1 gray,...      4.0\n",
              "79799   B00017UT6W  Great quality product.  A good bronze color an...      5.0\n",
              "149988  B000FSFOM6  I bought one of the 20X72 inch mats for my wif...      1.0\n",
              "342229  B0032SK8XG  I have no complaints about this item.  It is w...      5.0\n",
              "...            ...                                                ...      ...\n",
              "45574   B00008439Y  I bought the Roomba about 6 months ago. It has...      3.0\n",
              "297464  B0027IS6NG  I opted for this curtain because I didn't want...      5.0\n",
              "399715  B004BA8UWA  So far the king size has lasted and is definit...      3.0\n",
              "466357  B006SOHESS  I make frozen yogurt for my pups. They love it...      5.0\n",
              "367769  B003O47WZA  My daughter loves to bakes.  She especially en...      4.0\n",
              "\n",
              "[500 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pij7CrS6GNEM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "outputId": "e599040a-bdb8-40e7-eddc-ff944c8d4752"
      },
      "source": [
        "s2i = {w:i for i,w in enumerate(glove.keys())}\n",
        "i2s = {i:w for w,i in s2i.items()}\n",
        "i2v = {i:v for i,v in enumerate(glove.values())}\n",
        "stop_words = set(stopwords.words('english'))\n",
        "def intranslate(sent):\n",
        "  return np.array([s2i[word] if word in s2i.keys() else 0 for word in sent]).reshape(1,-1)\n",
        "\n",
        "def preprocessor (entry, stopwords):  \n",
        "  #1. remove stop words and punctuation marks:\n",
        "  tokenized = tokenizer.tokenize(entry)\n",
        "  tokenized = [w.lower() for w in tokenized  if not w in stop_words]\n",
        "  return tokenized\n",
        "\n",
        "def embed (sent, embbeding_dict):\n",
        "  return np.array([embbeding_dict[word] if word in embbeding_dict.keys() else np.zeros((1,300)) for word in sent])\n",
        "\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "def adj_count(entry):\n",
        "  return np.sum([1 if pos[1].startswith('JJ') else 0 for pos in np.array(nltk.pos_tag(tokenizer.tokenize(entry)))])\n",
        "\n",
        "def preprocessor_df (toy):\n",
        "\n",
        "  toy['tokenized'] = toy['reviewText'].apply(lambda x: preprocessor(x, stopwords))\n",
        "  toy['len'] = toy['tokenized'].apply(lambda x: len(x))\n",
        "  toy['joined'] = toy['tokenized'].apply(lambda x: ' '.join(x))\n",
        "  toy['int_sentences'] = toy.tokenized.apply(lambda x: intranslate(x))\n",
        "\n",
        "  toy['glove'] = toy.tokenized.apply(lambda x:embed (x, glove))\n",
        "\n",
        "  #add number of reviews as feature\n",
        "  toy = toy.join(toy.groupby('asin')['reviewText'].count(), on = 'asin',rsuffix = '_count')\n",
        "\n",
        "  # remove too long reviews\n",
        "  toy = toy[toy.len < toy.len.quantile(.95)]\n",
        "\n",
        "  #add product mean length as a feature\n",
        "  toy = toy.join(toy.groupby('asin')['len'].mean(), on = 'asin',rsuffix = '_mean')\n",
        "  \n",
        "  #count number of adhuctives in review\n",
        "  toy['num_adjs'] = toy.reviewText.apply(lambda x: adj_count(x))\n",
        "\n",
        "  return toy\n",
        "\n",
        "toy = preprocessor_df(toy)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Fb2YG8kbll2",
        "colab_type": "text"
      },
      "source": [
        "# part 2 - Bidirectional LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3U6D_VHocnM0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "outputId": "641bce49-fe6d-404b-dd8d-de88e9ca52e6"
      },
      "source": [
        "dt = toy\n",
        "dt.head()"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>asin</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>overall</th>\n",
              "      <th>tokenized</th>\n",
              "      <th>len</th>\n",
              "      <th>joined</th>\n",
              "      <th>int_sentences</th>\n",
              "      <th>glove</th>\n",
              "      <th>reviewText_count</th>\n",
              "      <th>len_mean</th>\n",
              "      <th>num_adjs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>431234</th>\n",
              "      <td>B005447JCY</td>\n",
              "      <td>I love my filter water in these. I washed the ...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>[i, love, filter, water, i, washed, soon, i, g...</td>\n",
              "      <td>20</td>\n",
              "      <td>i love filter water i washed soon i got weird ...</td>\n",
              "      <td>[[108, 185, 3268, 333, 108, 9734, 677, 108, 21...</td>\n",
              "      <td>[[0.18733, 0.40595, -0.51174, -0.55482, 0.0397...</td>\n",
              "      <td>1</td>\n",
              "      <td>20.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494773</th>\n",
              "      <td>B008MWKGH0</td>\n",
              "      <td>Bought 2 of these for our guest rooms (1 gray,...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>[bought, 2, guest, rooms, 1, gray, 1, camel, s...</td>\n",
              "      <td>24</td>\n",
              "      <td>bought 2 guest rooms 1 gray 1 camel silky smoo...</td>\n",
              "      <td>[[1475, 80, 2728, 1494, 66, 7305, 66, 23233, 2...</td>\n",
              "      <td>[[0.05361799999999999, 0.07041900000000001, -0...</td>\n",
              "      <td>1</td>\n",
              "      <td>24.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79799</th>\n",
              "      <td>B00017UT6W</td>\n",
              "      <td>Great quality product.  A good bronze color an...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>[great, quality, product, a, good, bronze, col...</td>\n",
              "      <td>14</td>\n",
              "      <td>great quality product a good bronze color heav...</td>\n",
              "      <td>[[158, 396, 493, 6, 112, 11144, 866, 2007, 188...</td>\n",
              "      <td>[[-0.093846, 0.58296, -0.019271, -0.0700720000...</td>\n",
              "      <td>2</td>\n",
              "      <td>17.5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149988</th>\n",
              "      <td>B000FSFOM6</td>\n",
              "      <td>I bought one of the 20X72 inch mats for my wif...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[i, bought, one, 20x72, inch, mats, wife, two,...</td>\n",
              "      <td>55</td>\n",
              "      <td>i bought one 20x72 inch mats wife two years ag...</td>\n",
              "      <td>[[108, 1475, 51, 0, 2786, 17173, 1119, 135, 14...</td>\n",
              "      <td>[[0.18733, 0.40595, -0.51174, -0.55482, 0.0397...</td>\n",
              "      <td>1</td>\n",
              "      <td>55.0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>342229</th>\n",
              "      <td>B0032SK8XG</td>\n",
              "      <td>I have no complaints about this item.  It is w...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>[i, complaints, item, it, well, made, looks, n...</td>\n",
              "      <td>14</td>\n",
              "      <td>i complaints item it well made looks nice serv...</td>\n",
              "      <td>[[108, 6346, 1308, 21, 133, 171, 628, 490, 397...</td>\n",
              "      <td>[[0.18733, 0.40595, -0.51174, -0.55482, 0.0397...</td>\n",
              "      <td>1</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              asin  ... num_adjs\n",
              "431234  B005447JCY  ...        3\n",
              "494773  B008MWKGH0  ...        4\n",
              "79799   B00017UT6W  ...        4\n",
              "149988  B000FSFOM6  ...        7\n",
              "342229  B0032SK8XG  ...        1\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUM8ElxtXbhM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import torch\n",
        "# from torch import nn\n",
        "# from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "from keras import Model\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential,Input\n",
        "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional,Concatenate\n",
        "from sklearn.model_selection import  train_test_split\n",
        "\n",
        "MAXLEN = np.max(data.len)\n",
        "BATCHSIZE = 32\n"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XW-nUusnpW5S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = dt.int_sentences\n",
        "X = [x[0] for x in X]\n",
        "X = sequence.pad_sequences(X, maxlen=MAXLEN, padding='post', truncating = 'post')\n",
        "X = np.concatenate([X , np.array(dt.len).reshape(-1,1) , np.array(dt.reviewText_count).reshape(-1,1),\n",
        "                np.array(dt.len_mean).reshape(-1,1),np.array(dt.num_adjs).reshape(-1,1)],axis = 1)\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,dt.overall,test_size = .25, random_state = 123)\n",
        "\n",
        "X_t1,X_t2 = X_train[:,:MAXLEN],X_train[:,MAXLEN:]\n"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwHO7AN3z-H_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "glove_matrix = np.array(list(glove.values())[:200000])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyKBwgCL4cbT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "glove_matrix = np.concatenate([np.zeros((1,300)),glove_matrix])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IA-bl22o_cUV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inp1,inp2 = Input(shape=(MAXLEN,)),Input(shape=(4,))\n",
        "x_emb = Embedding(glove_matrix.shape[0],300 ,weights=[glove_matrix],input_length =  MAXLEN, trainable = False)(inp1)\n",
        "x_emb = Bidirectional(LSTM(64))(x_emb)\n",
        "x_emb = Dropout(0.2)(x_emb)\n",
        "layer = Concatenate()([x_emb, inp2])\n",
        "output = Dense(1,input_dim = 128)(layer)\n",
        "model = Model([inp1,inp2], output)\n",
        "model.compile('adam', 'mse', metrics=['mse'])"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5bG1URSuOKA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "outputId": "7e959cbb-d6d2-4dc7-b98a-49d799199d64"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_23 (InputLayer)           (None, 138)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_13 (Embedding)        (None, 138, 300)     59998500    input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_13 (Bidirectional (None, 128)          186880      embedding_13[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 128)          0           bidirectional_13[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "input_24 (InputLayer)           (None, 4)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 132)          0           dropout_13[0][0]                 \n",
            "                                                                 input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (None, 1)            133         concatenate_12[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 60,185,513\n",
            "Trainable params: 187,013\n",
            "Non-trainable params: 59,998,500\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_YjJcLlsLvp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "082d2473-751b-4ffa-fc11-c938db383421"
      },
      "source": [
        "model.fit([X_train[:,:MAXLEN],X_train[:,MAXLEN:]], y_train,\n",
        "          batch_size=BATCHSIZE,\n",
        "          epochs=40,\n",
        "          validation_data=[[X_test[:,:MAXLEN],X_test[:,MAXLEN:]], y_test])"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 356 samples, validate on 119 samples\n",
            "Epoch 1/40\n",
            "356/356 [==============================] - 12s 34ms/step - loss: 115.3494 - mse: 115.3494 - val_loss: 69.8340 - val_mse: 69.8340\n",
            "Epoch 2/40\n",
            "356/356 [==============================] - 10s 28ms/step - loss: 67.0292 - mse: 67.0292 - val_loss: 46.8355 - val_mse: 46.8355\n",
            "Epoch 3/40\n",
            "356/356 [==============================] - 10s 28ms/step - loss: 47.0514 - mse: 47.0514 - val_loss: 37.2081 - val_mse: 37.2081\n",
            "Epoch 4/40\n",
            "356/356 [==============================] - 10s 27ms/step - loss: 38.5225 - mse: 38.5225 - val_loss: 32.4534 - val_mse: 32.4534\n",
            "Epoch 5/40\n",
            "356/356 [==============================] - 10s 27ms/step - loss: 28.8482 - mse: 28.8482 - val_loss: 25.8012 - val_mse: 25.8012\n",
            "Epoch 6/40\n",
            "356/356 [==============================] - 10s 28ms/step - loss: 18.3267 - mse: 18.3267 - val_loss: 19.1248 - val_mse: 19.1248\n",
            "Epoch 7/40\n",
            "356/356 [==============================] - 10s 28ms/step - loss: 11.7051 - mse: 11.7051 - val_loss: 8.9936 - val_mse: 8.9936\n",
            "Epoch 8/40\n",
            "356/356 [==============================] - 10s 27ms/step - loss: 6.4853 - mse: 6.4853 - val_loss: 6.6413 - val_mse: 6.6413\n",
            "Epoch 9/40\n",
            "356/356 [==============================] - 10s 27ms/step - loss: 4.8056 - mse: 4.8056 - val_loss: 4.1222 - val_mse: 4.1222\n",
            "Epoch 10/40\n",
            "356/356 [==============================] - 10s 28ms/step - loss: 3.6545 - mse: 3.6545 - val_loss: 4.4579 - val_mse: 4.4579\n",
            "Epoch 11/40\n",
            "356/356 [==============================] - 10s 28ms/step - loss: 3.1605 - mse: 3.1605 - val_loss: 2.8967 - val_mse: 2.8967\n",
            "Epoch 12/40\n",
            "356/356 [==============================] - 10s 27ms/step - loss: 2.1709 - mse: 2.1709 - val_loss: 2.5423 - val_mse: 2.5423\n",
            "Epoch 13/40\n",
            "356/356 [==============================] - 10s 28ms/step - loss: 1.6645 - mse: 1.6645 - val_loss: 2.2082 - val_mse: 2.2082\n",
            "Epoch 14/40\n",
            "356/356 [==============================] - 10s 27ms/step - loss: 1.5849 - mse: 1.5849 - val_loss: 1.8844 - val_mse: 1.8844\n",
            "Epoch 15/40\n",
            "356/356 [==============================] - 10s 28ms/step - loss: 1.3224 - mse: 1.3224 - val_loss: 1.7989 - val_mse: 1.7989\n",
            "Epoch 16/40\n",
            "356/356 [==============================] - 10s 28ms/step - loss: 1.3859 - mse: 1.3859 - val_loss: 1.7147 - val_mse: 1.7147\n",
            "Epoch 17/40\n",
            "356/356 [==============================] - 10s 27ms/step - loss: 1.1612 - mse: 1.1612 - val_loss: 1.8085 - val_mse: 1.8085\n",
            "Epoch 18/40\n",
            "356/356 [==============================] - 10s 28ms/step - loss: 1.0338 - mse: 1.0338 - val_loss: 1.6787 - val_mse: 1.6787\n",
            "Epoch 19/40\n",
            "356/356 [==============================] - 10s 27ms/step - loss: 0.9736 - mse: 0.9736 - val_loss: 1.7427 - val_mse: 1.7427\n",
            "Epoch 20/40\n",
            "356/356 [==============================] - 10s 27ms/step - loss: 0.8791 - mse: 0.8791 - val_loss: 1.6696 - val_mse: 1.6696\n",
            "Epoch 21/40\n",
            "356/356 [==============================] - 10s 28ms/step - loss: 0.8398 - mse: 0.8398 - val_loss: 1.5990 - val_mse: 1.5990\n",
            "Epoch 22/40\n",
            "356/356 [==============================] - 10s 28ms/step - loss: 0.7593 - mse: 0.7593 - val_loss: 1.6504 - val_mse: 1.6504\n",
            "Epoch 23/40\n",
            "356/356 [==============================] - 10s 27ms/step - loss: 0.7344 - mse: 0.7344 - val_loss: 1.6536 - val_mse: 1.6536\n",
            "Epoch 24/40\n",
            "356/356 [==============================] - 10s 29ms/step - loss: 0.5738 - mse: 0.5738 - val_loss: 1.7134 - val_mse: 1.7134\n",
            "Epoch 25/40\n",
            "356/356 [==============================] - 10s 28ms/step - loss: 0.6139 - mse: 0.6139 - val_loss: 1.8446 - val_mse: 1.8446\n",
            "Epoch 26/40\n",
            "356/356 [==============================] - 10s 28ms/step - loss: 0.6778 - mse: 0.6778 - val_loss: 2.1617 - val_mse: 2.1617\n",
            "Epoch 27/40\n",
            "356/356 [==============================] - 10s 28ms/step - loss: 0.7477 - mse: 0.7477 - val_loss: 1.8186 - val_mse: 1.8186\n",
            "Epoch 28/40\n",
            "356/356 [==============================] - 10s 28ms/step - loss: 0.6476 - mse: 0.6476 - val_loss: 1.8510 - val_mse: 1.8510\n",
            "Epoch 29/40\n",
            "356/356 [==============================] - 10s 27ms/step - loss: 0.5695 - mse: 0.5695 - val_loss: 1.7619 - val_mse: 1.7619\n",
            "Epoch 30/40\n",
            "356/356 [==============================] - 10s 28ms/step - loss: 0.5290 - mse: 0.5290 - val_loss: 1.8920 - val_mse: 1.8920\n",
            "Epoch 31/40\n",
            "356/356 [==============================] - 10s 27ms/step - loss: 0.5215 - mse: 0.5215 - val_loss: 1.7694 - val_mse: 1.7694\n",
            "Epoch 32/40\n",
            "356/356 [==============================] - 10s 29ms/step - loss: 0.4911 - mse: 0.4911 - val_loss: 1.9846 - val_mse: 1.9846\n",
            "Epoch 33/40\n",
            "356/356 [==============================] - 10s 28ms/step - loss: 0.4373 - mse: 0.4373 - val_loss: 1.7237 - val_mse: 1.7237\n",
            "Epoch 34/40\n",
            "356/356 [==============================] - 10s 28ms/step - loss: 0.4659 - mse: 0.4659 - val_loss: 1.8616 - val_mse: 1.8616\n",
            "Epoch 35/40\n",
            "356/356 [==============================] - 10s 28ms/step - loss: 0.4597 - mse: 0.4597 - val_loss: 1.7966 - val_mse: 1.7966\n",
            "Epoch 36/40\n",
            "356/356 [==============================] - 10s 28ms/step - loss: 0.4912 - mse: 0.4912 - val_loss: 1.9657 - val_mse: 1.9657\n",
            "Epoch 37/40\n",
            "356/356 [==============================] - 10s 28ms/step - loss: 0.3834 - mse: 0.3834 - val_loss: 1.8711 - val_mse: 1.8711\n",
            "Epoch 38/40\n",
            "356/356 [==============================] - 10s 27ms/step - loss: 0.3825 - mse: 0.3825 - val_loss: 1.9170 - val_mse: 1.9170\n",
            "Epoch 39/40\n",
            "356/356 [==============================] - 10s 28ms/step - loss: 0.3872 - mse: 0.3872 - val_loss: 1.9600 - val_mse: 1.9600\n",
            "Epoch 40/40\n",
            "356/356 [==============================] - 10s 28ms/step - loss: 0.3036 - mse: 0.3036 - val_loss: 1.7761 - val_mse: 1.7761\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f5e44c8a630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    }
  ]
}