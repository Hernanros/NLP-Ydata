{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBlwoCDzFKvC",
        "colab_type": "text"
      },
      "source": [
        "## Sentence reformulation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3O4LF511FKvG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "from gensim.models import KeyedVectors\n",
        "import scipy.spatial as sp\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "[nltk_data] Downloading package punkt to\n[nltk_data]     C:\\Users\\hman1\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     C:\\Users\\hman1\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "True"
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0CNgWHNFKva",
        "colab_type": "text"
      },
      "source": [
        "Load downloaded pretrained FastText vectors by gensim library:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUjXSLZFaoZ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fast = KeyedVectors.load_word2vec_format('../data/cc.en.300.vec')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('../data/Yelp.train.text','r+') as f:\n",
        "    yelp = f.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgER4oDyFKvt",
        "colab_type": "text"
      },
      "source": [
        "Compute similarity of two words using gensim"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XG36INqWFKvv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#We discussed different words, look and similarity of 'king' and 'queen' for example. Could you put it into context?\n",
        "pairs = [['king','queen'],['king','majesty'],['queen','majesty'],['man','woman'],['husband','wife'],['brother','sister'],['prince','princess'],['right','wrong'],['car','truck'],['porsche','subaru'],['porsche','bentley'],['superhero','villain'],['jesus','moses']]\n",
        "for pair in pairs:\n",
        "    w1,w2 = pair\n",
        "    sim = np.round(fast.similarity(w1,w2),3)\n",
        "    print(\"Similarity of {} and {} is: {:.3f}\".format(w1,w2,sim))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Similarity of king and queen is: 0.707\nSimilarity of king and majesty is: 0.445\nSimilarity of queen and majesty is: 0.376\nSimilarity of man and woman is: 0.766\nSimilarity of husband and wife is: 0.894\nSimilarity of brother and sister is: 0.818\nSimilarity of prince and princess is: 0.755\nSimilarity of right and wrong is: 0.562\nSimilarity of car and truck is: 0.648\nSimilarity of porsche and subaru is: 0.525\nSimilarity of porsche and bentley is: 0.546\nSimilarity of superhero and villain is: 0.595\nSimilarity of jesus and moses is: 0.592\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyXXjSI1FKv8",
        "colab_type": "text"
      },
      "source": [
        "Sentence tokenization. Split Yelp! texts into separate tokens (words and punctuation marks) by space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QACHJV98FKv_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#your code here\n",
        "word_tokens = nltk.tokenize.word_tokenize(yelp)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jU8-n4CjFKwO"
      },
      "source": [
        "Try part of speech tagging using [NLTK POS-tagger](https://www.nltk.org/book/ch05.html).\n",
        "The function returns list of tuples (word, POS_tag)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYLB_qAhFKwQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#your code here\n",
        "pos_tag = nltk.pos_tag(yelp)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_y0sEQvsFKwb",
        "colab_type": "text"
      },
      "source": [
        "Can you find the most similar word to the given? Can you write a method that returns a list of tuples (word, similarity) in order of decreasing similarity?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LHnV5FvFKwd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_most_sim_n (traget, vec_space, n, func = 'euclidean'):\n",
        "    vec = vec_space.wv.get_vector(traget).reshape(1,-1)\n",
        "    dist = sp.distance.cdist(vec_space.wv.vectors, vec, func)[:,0]\n",
        "    idxs=np.argsort(dist)[n:0:-1]\n",
        "    keys = list(vec_space.wv.vocab.keys()) \n",
        "    return [(keys[i],dist[i]) for i in idxs]"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "c:\\Y-Data\\NLP\\venv\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n  \nc:\\Y-Data\\NLP\\venv\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n  This is separate from the ipykernel package so we can avoid doing imports until\n[ 667106 1218377  134177 1096986  930533]\nc:\\Y-Data\\NLP\\venv\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n  \n"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "[('israelites', 1.2634099491206856),\n ('abrahams', 1.2596855196513037),\n ('joshua', 1.2592746645836506),\n ('malachi', 1.2513902803123798),\n ('bernice', 1.251252513206231)]"
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "find_most_sim_n ('moses',fast,5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnuD3D6eFKwu",
        "colab_type": "text"
      },
      "source": [
        "Let's do the simplest reformulation task. We just want to reformulate some sentences replacing an ajective with a similar one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nIKEXAEFKwv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def v(sentence):\n",
        "    # Sentence tokenization\n",
        "    tokenized_sentence = nltk.tokenize.word_tokenize(sentence)\n",
        "\n",
        "    # Part of speech tagging\n",
        "    POS_tagged_words = nltk.pos_tag(tokenized_sentence)\n",
        "\n",
        "    reformulated_sentence_words = []\n",
        "    for word, pos_tag in POS_tagged_words:\n",
        "        # If the word is adjective...\n",
        "        if pos_tag in ['JJR', 'JJS', 'JJ']:\n",
        "            try:\n",
        "                # ...look for the word most similar to the given and replace it\n",
        "                w = find_most_sim_n(word,fast,5)[np.random.randint(5)][0]\n",
        "                reformulated_sentence_words.append(w)\n",
        "                # your code here\n",
        "            except:\n",
        "                print('There is no {} word in FastText dictionary! ...'.format(word))\n",
        "        else:\n",
        "            reformulated_sentence_words.append(word)\n",
        "    # Join words list in a sentence\n",
        "    return ' '.join(reformulated_sentence_words)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "c:\\Y-Data\\NLP\\venv\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n  \nc:\\Y-Data\\NLP\\venv\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n  This is separate from the ipykernel package so we can avoid doing imports until\nc:\\Y-Data\\NLP\\venv\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n  \"\"\"\n"
        }
      ],
      "source": [
        "lst = []\n",
        "for i in range (5):\n",
        "    lst.append(reformulate_sentence('the stupid turd gave a press conference telling good americans to consume toxic bleach'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "['the asinine turd gave a press conference telling decent americans to consume poisonous bleach',\n 'the dumbass turd gave a press conference telling excellent americans to consume harmful bleach',\n 'the asinine turd gave a press conference telling good.Good americans to consume poisonous bleach',\n 'the moronic turd gave a press conference telling good.Good americans to consume harmful bleach',\n 'the asinine turd gave a press conference telling semi-good americans to consume noxious bleach']"
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "lst"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoC2U63bFKw3",
        "colab_type": "text"
      },
      "source": [
        "## Sentiment analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aL_NmEqWFKw5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cNVYcVYFKxB",
        "colab_type": "code",
        "outputId": "a6782a66-d26f-4d58-aa5a-83f9af263bd7",
        "colab": {}
      },
      "source": [
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "[nltk_data] Downloading package vader_lexicon to\n[nltk_data]     C:\\Users\\hman1\\AppData\\Roaming\\nltk_data...\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCzg4RHwFKxO",
        "colab_type": "text"
      },
      "source": [
        "VADER sentiment classifier from NLTK library. The range of sentiment is from -1 to 1 where -1 is negative, 0 is neutral and 1 is positive\n",
        "\n",
        "Hutto, C.J. & Gilbert, E.E. (2014). VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text. Eighth International Conference on Weblogs and Social Media (ICWSM-14). Ann Arbor, MI, June 2014."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5G1mjf4_FKxP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentiment_analyzer = SentimentIntensityAnalyzer()"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yIhf8tAFKxb",
        "colab_type": "text"
      },
      "source": [
        "Read the dataset text file line by line and put lines into the list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUiv4yQeFKxc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#your code here\n",
        "split_sent = yelp.split(\"\\n\")\n",
        "split_sent[:10]"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "['i was sadly mistaken .',\n 'so on to the hoagies , the italian is general run of the mill .',\n 'minimal meat and a ton of shredded lettuce .',\n 'nothing really special & not worthy of the $ _num_ price tag .',\n 'second , the steak hoagie , it is atrocious .',\n 'i had to pay $ _num_ to add cheese to the hoagie .',\n 'she told me there was a charge for the dressing on the side .',\n 'are you kidding me ?',\n 'i was not going to pay for the dressing on the side .',\n 'i ordered it without lettuce , tomato , onions , or dressing .']"
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIm1mHFZFKx1",
        "colab_type": "text"
      },
      "source": [
        "Read Yelp dataset from text file and get 1000 random sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRbnz_oLFKx4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#your code here\n",
        "samp = np.array(split_sent)[np.random.choice(range(len(split_sent)),1000,replace=False)]\n",
        "samp[:10]"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "array(['she really should be fired .', 'best pizza in pittsburgh .',\n       'i definitely will use them again .', 'thank you .',\n       'it was only downhill from there .',\n       \"hands down the best ice cream i 've had in ages .\",\n       'excellent welcome from front desk when we arrived .',\n       'well worth the money and experience to try out sushi and hibachi .',\n       'the donuts were very fresh and warm .',\n       'i will drive a longer distance to avoid this location .'],\n      dtype='<U108')"
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmWtFpjGFKyE",
        "colab_type": "text"
      },
      "source": [
        "Compute average sentiment of 1000 sentences sentences set by VADER sentiment classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "the average compunded sentiment that those little shits on yelp write is: 0.25\n"
        }
      ],
      "source": [
        "av_sent = np.mean([sentiment_analyzer.polarity_scores(sent)['compound'] for sent in samp])\n",
        "\n",
        "print(f'the average compunded sentiment that those little shits on yelp write is: {np.round(av_sent,2)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LwHdcA3FKyl",
        "colab_type": "text"
      },
      "source": [
        "Reformulate sentences and compute average sentiment again. Try to come up with ways to make senteces more positive on average. What about more negative? Can you come up with some interesting experiment on this data with POS-tagged reformulations?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XjoCHG0FKyn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#your code here\n",
        "import tqdm\n",
        "reformulated = []\n",
        "pbar = tqdm.tqdm(total=1000, position= 0 , leave = True)\n",
        "for sent in samp:\n",
        "    reformulated.append(reformulate_sentence(sent))\n",
        "    pbar.update()\n",
        "pbar.close()\n",
        "av_sent = np.mean([sentiment_analyzer.polarity_scores(sent)['compound'] for sent in reformulated])\n",
        "print(f'the average compunded sentiment for the rformulated sentences is: {np.round(av_sent,2)}')"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "0%|          | 0/1000 [00:00<?, ?it/s]c:\\Y-Data\\NLP\\venv\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n  \nc:\\Y-Data\\NLP\\venv\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n  This is separate from the ipykernel package so we can avoid doing imports until\nc:\\Y-Data\\NLP\\venv\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n  \"\"\"\n 14%|█▎        | 136/1000 [06:34<39:20,  2.73s/it]There is no a/c word in FastText dictionary! ...\n 16%|█▌        | 162/1000 [08:06<56:50,  4.07s/it]There is no _num_ word in FastText dictionary! ...\n 22%|██▎       | 225/1000 [11:19<1:08:29,  5.30s/it]There is no _num_ word in FastText dictionary! ...\n 30%|██▉       | 299/1000 [14:48<40:51,  3.50s/it]There is no _num_ word in FastText dictionary! ...\n 36%|███▌      | 355/1000 [17:31<30:10,  2.81s/it]There is no _num_ word in FastText dictionary! ...\n 38%|███▊      | 382/1000 [18:52<31:46,  3.09s/it]There is no _num_ word in FastText dictionary! ...\n 41%|████▏     | 414/1000 [20:34<27:06,  2.78s/it]There is no _num_ word in FastText dictionary! ...\n 45%|████▌     | 453/1000 [22:24<22:49,  2.50s/it]There is no _num_ word in FastText dictionary! ...\n 49%|████▉     | 494/1000 [24:12<32:35,  3.87s/it]There is no _num_ word in FastText dictionary! ...\n 50%|████▉     | 497/1000 [24:21<28:34,  3.41s/it]There is no _num_ word in FastText dictionary! ...\n 55%|█████▍    | 548/1000 [27:13<22:43,  3.02s/it]There is no _num_ word in FastText dictionary! ...\n 55%|█████▌    | 550/1000 [27:19<22:17,  2.97s/it]There is no _num_ word in FastText dictionary! ...\n 59%|█████▉    | 589/1000 [29:21<22:35,  3.30s/it]There is no _num_ word in FastText dictionary! ...\n 63%|██████▎   | 626/1000 [31:16<19:58,  3.20s/it]There is no _num_ word in FastText dictionary! ...\n 64%|██████▍   | 639/1000 [31:51<24:16,  4.03s/it]There is no _num_ word in FastText dictionary! ...\n 69%|██████▊   | 687/1000 [34:32<14:43,  2.82s/it]There is no _num_ word in FastText dictionary! ...\n 71%|███████▏  | 713/1000 [35:39<16:28,  3.45s/it]There is no _num_ word in FastText dictionary! ...\n 79%|███████▉  | 789/1000 [38:45<12:56,  3.68s/it]There is no _num_ word in FastText dictionary! ...\n 94%|█████████▍| 941/1000 [46:50<03:08,  3.19s/it]There is no _num_ word in FastText dictionary! ...\n 99%|█████████▉| 992/1000 [48:38<00:12,  1.61s/it]There is no _num_ word in FastText dictionary! ...\n100%|██████████| 1000/1000 [48:55<00:00,  2.94s/it]the average compunded sentiment for the rformulated sentences is: 0.19\n\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "the average compunded sentiment for the rformulated sentences is: 0.19\n"
        }
      ],
      "source": [
        "print(f'the average compunded sentiment for the rformulated sentences is: {np.round(av_sent,2)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## changing the average score of the sentence\n",
        "In order to make a sentence more positive (or negative)\n",
        "1. We can look for the most negative words in a sentence and pick the n-most negative words. for each of those words we can look for the most similar words and replace the original word with the highest sentiment - scoring from the list of most similar words (given that the score of the highest sentiment scoring similar word is higher than the score of the original one). <br>\n",
        "Of course that if we want to increase the negativity of a sentence we will replace the most positive words with lass positive similar words.\n",
        "2. we can use compund adjectives, we can randomly add aditional adjectives for any existing adjactive in the original sentence.\n",
        "\n",
        "## POS reformulations expiriments\n",
        "1. before submitting reviews on YELP, analyze the sentences and suggest alternative phrasings, ask the user if the alternative sentence could replace the original phrasing. that way we can examine the effect of words that users are more used to use in their day to day life on the sentiment calculation.\n",
        "2. take the original reviews and give them to random readers to rate the overall text. use those measurements as a baseline. then isolate different POS tags and refurmulate sentences to be more positive\\more negative and have another group of subjects rate those reviews. this expirement will allow us to get an intuition to which POS is the most significant in determinating the tone of the review.\n",
        "\n",
        "**Side point**: when replacing a word in a sentence we should check if the similar words can be used as a similar POS tag. some words cannot be used as verbs as well as adjactives, and we should control for that.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5-final"
    },
    "colab": {
      "name": "Hernan Rosenblum - NLP_HW1.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}